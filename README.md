# conversationsplit

Splits an mp3/wav/recording, like a podcast, by speaker, using AssemblyAI, into separate recordings.  Useful for audio2face and audio2gesture models.

I build this to split the audio generated by Google's NotebookLM files into separate audio files per speaker to animate avatars with nVidia's audio2face and audio2gesture models.

The specified file is sent to the AssemblyAI service, which identifies the speech segments, and then the script splits up the source file with the speech segments identified by AssemblyAI.

## Requirements

- Python
- AssemblyAI API credentials - obtain them from [https://www.assemblyai.com/](https://www.assemblyai.com/)

## Installation

```
python3 -m pip install -r requirements.txt
```

Fill in the values for your environment in sampledotenvfile, and copy to .env 

## Usage

```
python3 conversationsplit.py --filename=notebook.wav --numspeakers=2
```
where notebook.wav is the audio file you want to split up, and 2 is the number of people speaking in the audio file.

The process outputs files named: conversationsplit #.wav
